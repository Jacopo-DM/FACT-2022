{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FACT15.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import tarfile\n",
        "import pickle\n",
        "import shutil\n",
        "# don't move this cell"
      ],
      "metadata": {
        "id": "rieuwKH7MOwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you open the notebook on Colab, pull the all code files via git clone\n",
        "# comment out if you are on a local machine\n",
        "!git clone https://github.com/Jacopo-DM/FACT-2022.git\n",
        "!mv  -v FACT-2022/* /content/\n",
        "!rm -r FACT-2022"
      ],
      "metadata": {
        "id": "C-H_N6sghnPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "olkF2Emh2O49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download datasets and model files"
      ],
      "metadata": {
        "id": "84blpVA_br8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUB-200 Dataset"
      ],
      "metadata": {
        "id": "5GNxYY7rIkbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('data'):\n",
        "    os.mkdir('data')\n",
        "\n",
        "if not os.path.exists('data/CUB200'):\n",
        "    print('Beginning file download with urllib2...')\n",
        "    url = 'https://data.deepai.org/CUB200(2011).zip'\n",
        "    urllib.request.urlretrieve(url, 'data/CUB200.zip')\n",
        "\n",
        "    with zipfile.ZipFile('data/CUB200.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('data/CUB200')\n",
        "\n",
        "    my_tar = tarfile.open('data/CUB200/CUB_200_2011.tgz')\n",
        "    my_tar.extractall('data/CUB200/') # specify which folder to extract to\n",
        "    my_tar.close()\n",
        "\n",
        "    os.remove('data/CUB200.zip')\n",
        "    os.remove('data/CUB200/CUB_200_2011.tgz')"
      ],
      "metadata": {
        "id": "G07gsOJc1a6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the trained model files and the ImageNet ILSVRC 2012-2017 Challenge validation set. \n",
        "\n",
        "For the full (not needed for this result notebook) ImageNet ILSVRC dataset including training data, see https://www.kaggle.com/c/imagenet-object-localization-challenge/data."
      ],
      "metadata": {
        "id": "CND8DRY3ImVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IMPORTANT NOTE\n",
        "\n",
        "All files can be found in this public drive: https://drive.google.com/drive/folders/1RpmzTNrc8i1eSu7C-Mctdhy2SZiXbH80?usp=sharing\n",
        "\n",
        "Please use this Google Drive link and copy the files to the correct directories so they can be unzipped by the code. The zipfiles should be in the following directories:\n",
        "```\n",
        "imgnet_val.zip in data/\n",
        "val_annotations.zip in data/\n",
        "model_files_archive.zip in /    (the main directory of the project)\n",
        "\n",
        "```\n",
        "\n",
        "The ```data/``` directory is only created when the previous cell for downloading CUB-200 is done running.\n",
        "\n",
        "#### In case you use Google Colab (fastest method)\n",
        "In case of Colab you can mount your Google Drive. You should first make a copy of all files in the shared link to your own Google Drive. Eventually, you can access these files in Colab after you have mounted Google Drive, see the code below.\n"
      ],
      "metadata": {
        "id": "RxtPwwrm_4kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Only use this when in colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BpTSMggiBp5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use this when using colab with mounted google drive and you copied the zip files to you own google drive\n",
        "# Change to correct path after Google Drive was mounted\n",
        "# This code moves the zip files into the right directories for extracting\n",
        "!rsync -ah --progress drive/MyDrive/imgnet_val.zip data/\n",
        "!rsync -ah --progress drive/MyDrive/val_annotations.zip data/\n",
        "!rsync -ah --progress drive/MyDrive/model_files_archive.zip /content/"
      ],
      "metadata": {
        "id": "iKf4sae2nMlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### UNZIP CODE ####\n",
        "\n",
        "# unzip imagenet images\n",
        "if not os.path.exists('data/imagenet'):\n",
        "    with zipfile.ZipFile('data/imgnet_val.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('data/imagenet/')\n",
        "\n",
        "if os.path.exists('data/imgnet_val.zip'):\n",
        "    os.remove('data/imgnet_val.zip')\n",
        "\n",
        "\n",
        "# unzip annotations\n",
        "with zipfile.ZipFile('data/val_annotations.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('data/imagenet/annotations')\n",
        "\n",
        "if os.path.exists('data/val_annotations.zip'):\n",
        "    os.remove('data/val_annotations.zip')\n",
        "\n",
        "# create empty train data folder to avoid downloading \n",
        "# the full size dataset incl. training.\n",
        "with open('categories.pickle', 'rb') as f:\n",
        "    cats = pickle.load(f)\n",
        "if not os.path.exists('data/imagenet/train'):\n",
        "    os.mkdir('data/imagenet/train')\n",
        "    for cat in cats:\n",
        "        os.mkdir('data/imagenet/train/{}'.format(cat))\n",
        "\n",
        "# download trained model files\n",
        "if not os.path.exists('trained_model_files'):\n",
        "    os.mkdir('trained_model_files')\n",
        "with zipfile.ZipFile('model_files_archive.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('trained_model_files/')\n",
        "\n",
        "shutil.rmtree('trained_model_files/__MACOSX')\n",
        "\n",
        "if os.path.exists('model_files_archive.zip'):\n",
        "    os.remove('model_files_archive.zip')\n",
        "\n",
        "#####################################"
      ],
      "metadata": {
        "id": "vDctv4QUnHwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate metrics and visualize results"
      ],
      "metadata": {
        "id": "f4yw-zLtlsaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please make sure you are running this on a GPU (we used Google Colab).\n",
        "\n",
        "If you run into an error like this:\n",
        "\n",
        "```RuntimeError: unexpected EOF, expected 5253807 more bytes. The file might be corrupted```\n",
        "\n",
        "something went wrong with unzipping or copying the model files which made them corrupt. In this case you should download all model files via this link:\n",
        "\n",
        "https://www.dropbox.com/sh/fo9kqm0fgjhoq5j/AAA-A2cznqSsZuP31iLvqWKta?dl=0\n",
        "\n",
        "When the files were downloaded, please store them in a directory called ```trained_model_files```. The directory ```trained_model_files``` should be stored in the main directory of the project."
      ],
      "metadata": {
        "id": "0w_D9GVj_UNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Parameter setup"
      ],
      "metadata": {
        "id": "L_w2K3cTmFxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for ImageNet with positive SCOUTER for different lambda values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WztVWix_KFZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_imgnet_n_100_lambda1 = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size','70', '--epochs','20', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'false', '--loss_status','1', '--slots_per_class','1', '--lambda_value','1',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','0', '--dataset_dir','data/imagenet/', '--output_dir','trained_model_files/ImageNet_use_slot_checkpoint_classes100_lambda1.pth']\n",
        "\n",
        "params_imgnet_n_100_lambda3 = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size','70', '--epochs','20', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'false', '--loss_status','1', '--slots_per_class','1', '--lambda_value','3',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','0', '--dataset_dir','data/imagenet/', '--output_dir','trained_model_files/ImageNet_use_slot_checkpoint_classes100_lambda3.pth']\n",
        "\n",
        "params_imgnet_n_100_lambda10 = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size','70', '--epochs','20', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'false', '--loss_status','1', '--slots_per_class','1', '--lambda_value','10',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','0', '--dataset_dir','data/imagenet/', '--output_dir','trained_model_files/ImageNet_use_slot_checkpoint_classes100_lambda10.pth']\n",
        "\n",
        "param_list_pos = [params_imgnet_n_100_lambda1, params_imgnet_n_100_lambda3, params_imgnet_n_100_lambda10]"
      ],
      "metadata": {
        "id": "Xptyu4AdVyDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for ImageNet with negative SCOUTER for different lambda values\n"
      ],
      "metadata": {
        "id": "lzCEd5OhKOan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_imgnet_n_100_lambda1_neg = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size','70', '--epochs','20', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'false', '--loss_status','-1', '--slots_per_class','1', '--lambda_value','1',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','0', '--dataset_dir','data/imagenet/', '--output_dir','trained_model_files/ImageNet_use_slot_negative_checkpoint_classes100_lambda1.pth']\n",
        "\n",
        "params_imgnet_n_100_lambda3_neg = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size','70', '--epochs','20', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'false', '--loss_status','-1', '--slots_per_class','1', '--lambda_value','3',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','0', '--dataset_dir','data/imagenet/', '--output_dir','trained_model_files/ImageNet_use_slot_negative_checkpoint_classes100_lambda3.pth']\n",
        "\n",
        "params_imgnet_n_100_lambda10_neg = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size','70', '--epochs','20', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'false', '--loss_status','-1', '--slots_per_class','1', '--lambda_value','10',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','0', '--dataset_dir','data/imagenet/', '--output_dir','trained_model_files/ImageNet_use_slot_negative_checkpoint_classes100_lambda10.pth']\n",
        "\n",
        "param_list_neg = [params_imgnet_n_100_lambda1_neg, params_imgnet_n_100_lambda3_neg, params_imgnet_n_100_lambda10_neg]"
      ],
      "metadata": {
        "id": "to7u6xNHKY7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUB-200 positive SCOUTER"
      ],
      "metadata": {
        "id": "FBxlwLGMMXfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_cub_n_100_lambda10 = ['--dataset', 'CUB200', '--model', 'resnest26d', '--batch_size','64', '--epochs','150', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'true', '--loss_status','1', '--slots_per_class','5', '--lambda_value','10',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','2', '--dataset_dir','data/CUB200/CUB_200_2011', '--output_dir','trained_model_files/CUB200_use_slot_checkpoint_classes100_lambda10.pth']\n",
        "\n",
        "param_list_pos_cub = [params_cub_n_100_lambda10]"
      ],
      "metadata": {
        "id": "DxqbwFW0KDht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUB-200 negative SCOUTER"
      ],
      "metadata": {
        "id": "cTiQ_JmwMZtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_cub_n_100_lambda10_neg = ['--dataset', 'CUB200', '--model', 'resnest26d', '--batch_size','64', '--epochs','150', '--num_classes','100',\n",
        "'--use_slot','true', '--use_pre', 'true', '--loss_status','-1', '--slots_per_class','3', '--lambda_value','10',\n",
        "'--vis','true', '--power', '2', '--to_k_layer', '3', '--channel', '2048', '--freeze_layers','2', '--dataset_dir','data/CUB200/CUB_200_2011', '--output_dir','trained_model_files/CUB200_use_slot_negative_checkpoint_classes100_lambda10.pth']\n",
        "\n",
        "param_list_neg_cub = [params_cub_n_100_lambda10_neg]"
      ],
      "metadata": {
        "id": "Yw1N15AsMcir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for the metrics of positive ImageNet SCOUTER\n",
        " "
      ],
      "metadata": {
        "id": "b4Q_162gZDJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_Imagenet100_positive_lambda10 = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size', '70', '--epochs', '1', '--num_classes', '100', '--use_slot', 'True', '--use_pre', 'false',\n",
        "'--loss_status', '1', '--slots_per_class', '1', '--power', '2', '--to_k_layer','3', '--lambda_value', '10', '--vis', 'false','--channel', '2048', '--freeze_layers', '0', \n",
        "'--dataset_dir', 'data/imagenet/', '--resume', 'true', '--annotations_dir', 'data/imagenet/annotations/', '--pre_dir', 'trained_model_files/ImageNet_use_slot_checkpoint_classes100_lambda10.pth']\n",
        "\n",
        "eval_Imagenet100_positive_lambda3 =['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size', '70', '--epochs', '1', '--num_classes', '100', '--use_slot', 'True', '--use_pre', 'false',\n",
        "'--loss_status', '1', '--slots_per_class', '1', '--power', '2', '--to_k_layer','3', '--lambda_value', '3', '--vis', 'false','--channel', '2048', '--freeze_layers', '0', \n",
        "'--dataset_dir', 'data/imagenet/', '--resume', 'true', '--annotations_dir', 'data/imagenet/annotations/', '--pre_dir', 'trained_model_files/ImageNet_use_slot_checkpoint_classes100_lambda3.pth']\n",
        "\n",
        "eval_Imagenet100_positive_lambda1 =['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size', '70', '--epochs', '1', '--num_classes', '100', '--use_slot', 'True', '--use_pre', 'false',\n",
        "'--loss_status', '1', '--slots_per_class', '1', '--power', '2', '--to_k_layer','3', '--lambda_value', '1', '--vis', 'false','--channel', '2048', '--freeze_layers', '0', \n",
        "'--dataset_dir', 'data/imagenet/', '--resume', 'true', '--annotations_dir', 'data/imagenet/annotations/', '--pre_dir', 'trained_model_files/ImageNet_use_slot_checkpoint_classes100_lambda1.pth']"
      ],
      "metadata": {
        "id": "rLN9-uzkZAvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for the metrics of negative ImageNet SCOUTER"
      ],
      "metadata": {
        "id": "ZnOUphDY5eOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_Imagenet100_negative_lambda10 = ['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size', '70', '--epochs', '1', '--num_classes', '100', '--use_slot', 'True', '--use_pre', 'false',\n",
        "'--loss_status', '-1', '--slots_per_class', '1', '--power', '2', '--to_k_layer','3', '--lambda_value', '10', '--vis', 'false','--channel', '2048', '--freeze_layers', '0', \n",
        "'--dataset_dir', 'data/imagenet/', '--resume', 'true', '--annotations_dir', 'data/imagenet/annotations/', '--pre_dir', 'trained_model_files/ImageNet_use_slot_negative_checkpoint_classes100_lambda10.pth']\n",
        "\n",
        "eval_Imagenet100_negative_lambda3 =['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size', '70', '--epochs', '1', '--num_classes', '100', '--use_slot', 'True', '--use_pre', 'false',\n",
        "'--loss_status', '-1', '--slots_per_class', '1', '--power', '2', '--to_k_layer','3', '--lambda_value', '3', '--vis', 'false','--channel', '2048', '--freeze_layers', '0', \n",
        "'--dataset_dir', 'data/imagenet/', '--resume', 'true', '--annotations_dir', 'data/imagenet/annotations/', '--pre_dir', 'trained_model_files/ImageNet_use_slot_negative_checkpoint_classes100_lambda3.pth']\n",
        "\n",
        "eval_Imagenet100_negative_lambda1 =['--dataset', 'ImageNet', '--model', 'resnest26d', '--batch_size', '70', '--epochs', '1', '--num_classes', '100', '--use_slot', 'True', '--use_pre', 'false',\n",
        "'--loss_status', '-1', '--slots_per_class', '1', '--power', '2', '--to_k_layer','3', '--lambda_value', '1', '--vis', 'false','--channel', '2048', '--freeze_layers', '0', \n",
        "'--dataset_dir', 'data/imagenet/', '--resume', 'true', '--annotations_dir', 'data/imagenet/annotations/', '--pre_dir', 'trained_model_files/ImageNet_use_slot_negative_checkpoint_classes100_lambda1.pth']"
      ],
      "metadata": {
        "id": "ccYyTpJe4pwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization of increasing lambda values"
      ],
      "metadata": {
        "id": "Ojq1RmRGmJAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Positive SCOUTER on ImageNet with 100 classes"
      ],
      "metadata": {
        "id": "oPL8X-zxFPhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "\n",
        "#\n",
        "# specifiy datapoint to show results on ImageNet or CUB-200\n",
        "# NOTE: don't fill in a higher number than the batchsize for the first number in the tuple\n",
        "# NOTE: also, the second number can't be higher than the batch size\n",
        "datapoint = (2, 54)\n",
        "\n",
        "# when batch_size = 70\n",
        "assert datapoint[1] < 70\n",
        "from test import *\n",
        "\n",
        "# create the visualizations\n",
        "preds = []\n",
        "target_labels = []\n",
        "for p in param_list_pos:\n",
        "    pred, target_label = create_vis(p, datapoint)\n",
        "    preds.append(pred)\n",
        "    target_labels.append(target_label)\n",
        "\n",
        "print(preds, target_labels)\n",
        "\n",
        "# plot\n",
        "fig = plt.figure(figsize=(20,40))  \n",
        "lambda_values = [1, 3, 10]\n",
        "img = mpimg.imread('sloter/vis/image.png')\n",
        "plt.subplot(1,4, 1) \n",
        "plt.title('Original image')\n",
        "plt.imshow(img)\n",
        "for index, l in enumerate(lambda_values):\n",
        "    img = mpimg.imread('sloter/vis/slot_mask_{}_lambda_{}.png'.format(target_labels[index], l))\n",
        "    plt.subplot(1,4, index+2) \n",
        "    plt.title('$\\lambda = {}$'.format(l))\n",
        "    plt.imshow(img)\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UILqsy_MX_Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Negative SCOUTER on ImageNet with 100 classes"
      ],
      "metadata": {
        "id": "1nkzFWS_FUf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "\n",
        "#\n",
        "# specifiy datapoint to show results on ImageNet or CUB-200\n",
        "# NOTE: don't fill in a higher number than the number of samples in a batch\n",
        "# NOTE: also, the second number can't be higher than the batch size\n",
        "datapoint = (24, 25)\n",
        "\n",
        "# when batch_size = 70\n",
        "assert datapoint[1] < 70\n",
        "\n",
        "from test import *\n",
        "# create the visualizations\n",
        "preds = []\n",
        "target_labels = []\n",
        "for p in param_list_neg:\n",
        "    pred, target_label = create_vis(p, datapoint)\n",
        "    preds.append(pred)\n",
        "    target_labels.append(target_label)\n",
        "\n",
        "print(preds, target_labels)\n",
        "\n",
        "# plot\n",
        "fig = plt.figure(figsize=(20,40))  \n",
        "lambda_values = [1, 3, 10]\n",
        "img = mpimg.imread('sloter/vis/image.png')\n",
        "plt.subplot(1,4, 1) \n",
        "plt.title('Original image')\n",
        "plt.imshow(img)\n",
        "for index, l in enumerate(lambda_values):\n",
        "    img = mpimg.imread('sloter/vis/slot_mask_{}_lambda_{}.png'.format(preds[index], l))\n",
        "    plt.subplot(1,4, index+2) \n",
        "    plt.title('$\\lambda = {}$'.format(l))\n",
        "    plt.imshow(img)\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "muGkCnvXM3bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUB-200 visualization for lambda = 10"
      ],
      "metadata": {
        "id": "brxljMh4FcsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Positive SCOUTER on CUB-200 with 100 classes"
      ],
      "metadata": {
        "id": "f7_tyn3wFYvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "\n",
        "#\n",
        "# specifiy datapoint to show results on ImageNet or CUB-200\n",
        "# NOTE: don't fill in a higher number than the batchsize for the first number in the tuple\n",
        "# NOTE: also, the second number can't be higher than the batch size\n",
        "datapoint = (24, 26)\n",
        "\n",
        "# when batch_size = 70\n",
        "assert datapoint[1] < 70\n",
        "\n",
        "from test import *\n",
        "# create the visualizations\n",
        "preds = []\n",
        "target_labels = []\n",
        "for p in param_list_pos_cub:\n",
        "    pred, target_label = create_vis(p, datapoint)\n",
        "    preds.append(pred)\n",
        "    target_labels.append(target_label)\n",
        "\n",
        "print(preds, target_labels)\n",
        "\n",
        "# plot\n",
        "fig = plt.figure(figsize=(20,40))  \n",
        "lambda_values = [10]\n",
        "img = mpimg.imread('sloter/vis/image.png')\n",
        "plt.subplot(1,4, 1) \n",
        "plt.title('Original image')\n",
        "plt.imshow(img)\n",
        "for index, l in enumerate(lambda_values):\n",
        "    img = mpimg.imread('sloter/vis/slot_mask_{}_lambda_{}.png'.format(target_labels[index], l))\n",
        "    plt.subplot(1,4, index+2) \n",
        "    plt.title('$\\lambda = {}$'.format(l))\n",
        "    plt.imshow(img)\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-4mUNlHAM64n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Positive SCOUTER on CUB-200 with 100 classes"
      ],
      "metadata": {
        "id": "wjWjT5UzFihO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "\n",
        "# specifiy datapoint to show results on ImageNet or CUB-200\n",
        "# NOTE: don't fill in a higher number than the batchsize for the first number in the tuple\n",
        "# NOTE: also, the second number can't be higher than the batch size\n",
        "datapoint = (24, 26)\n",
        "\n",
        "# when batch_size = 70\n",
        "assert datapoint[1] < 70\n",
        "\n",
        "from test import *\n",
        "# create the visualizations\n",
        "preds = []\n",
        "target_labels = []\n",
        "for p in param_list_neg_cub:\n",
        "    pred, target_label = create_vis(p, datapoint)\n",
        "    preds.append(pred)\n",
        "    target_labels.append(target_label)\n",
        "\n",
        "print(preds, target_labels)\n",
        "\n",
        "# plot\n",
        "fig = plt.figure(figsize=(20,40))  \n",
        "lambda_values = [10]\n",
        "img = mpimg.imread('sloter/vis/image.png')\n",
        "plt.subplot(1,4, 1) \n",
        "plt.title('Original image')\n",
        "plt.imshow(img)\n",
        "for index, l in enumerate(lambda_values):\n",
        "    img = mpimg.imread('sloter/vis/slot_mask_{}_lambda_{}.png'.format(target_labels[index], l))\n",
        "    plt.subplot(1,4, index+2) \n",
        "    plt.title('$\\lambda = {}$'.format(l))\n",
        "    plt.imshow(img)\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W1h__lEsNYoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation curves"
      ],
      "metadata": {
        "id": "M6HU9GqjwQvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the training and validation accuracy + loss curves for CUB-200 dataset, trained on different numbers of classes on ResNest50.\n",
        "We used lambda value 10 for positive SCOUTER and lambda value 1 for negative SCOUTER."
      ],
      "metadata": {
        "id": "NX6HhLCPHQ_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('FC_cub200.pickle', 'rb') as handle:\n",
        "    FC = pickle.load(handle)\n",
        "\n",
        "with open('neg_cub200_L1.pickle', 'rb') as handle:\n",
        "    neg_L1 = pickle.load(handle)\n",
        "\n",
        "with open('pos_cub200_L10.pickle', 'rb') as handle:\n",
        "    pos_L10 = pickle.load(handle)"
      ],
      "metadata": {
        "id": "t9QDZX0vHCwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = [50, 75, 100]\n",
        "epochs = 150\n",
        "  \n",
        "\n",
        "for i, d in enumerate([FC, neg_L1, pos_L10]):\n",
        "    fig = plt.figure(figsize=(20,5))\n",
        "    for i, n in enumerate(n_classes):\n",
        "\n",
        "        x = range(1, epochs+1)\n",
        "        plt.subplot(1,3, i+1) \n",
        "        y = d[2][n]\n",
        "        plt.plot(x,y)\n",
        "        y = d[3][n]\n",
        "        plt.plot(x,y)\n",
        "        plt.title(f'Number of classes = {n}')\n",
        "        plt.legend(['Training accuracy', 'Validation accuracy'])\n",
        "        plt.xlabel('Number of epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KssKc50AHss2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the validation accuracy vs the number of classes for CUB-200 positive SCOUTER with lambda value 10."
      ],
      "metadata": {
        "id": "68eRa2HFb8FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the number 0.628 was noted from a training output of the positive scouter file that got corrupted\n",
        "accs = [0.628, pos_L10[3][50][-1], pos_L10[3][75][-1], pos_L10[3][100][-1]]\n",
        "\n",
        "xs = [25, 50, 75, 100]\n",
        "\n",
        "\n",
        "plt.plot(xs, accs)\n",
        "plt.title('Validation accuracy as number of classes increases')\n",
        "plt.xlabel('Number of classes')\n",
        "plt.ylabel('Validation accuracy')"
      ],
      "metadata": {
        "id": "17aTTKb9OiKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate metrics for ImageNet ResNest26 with 100 classes (area size, precision, IAUC, DAUC, sensitivity)\n",
        "\n",
        "NOTE: this can take 1-2 hours per evaluation, in case of memory issues (like with DataLoader or other out of memory errors), \n",
        "\n",
        "please add/set argument --num_workers to 0 in the parameter list for the specific run, if that doesn't work you should run it on a more powerful GPU with more RAM (like on Google Cloud or Colab Pro)."
      ],
      "metadata": {
        "id": "HlAlmQavMxay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from get_results import *\n",
        "\n",
        "# calculate metrics for positive scouter with lambda = 1\n",
        "calculate_metrics(eval_Imagenet100_positive_lambda1)"
      ],
      "metadata": {
        "id": "9RIx6oBBMw7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate metrics for positive scouter with lambda = 3\n",
        "calculate_metrics(eval_Imagenet100_positive_lambda3)"
      ],
      "metadata": {
        "id": "Bi_8_EgTOAoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate metrics for positive scouter with lambda = 10\n",
        "calculate_metrics(eval_Imagenet100_positive_lambda10)"
      ],
      "metadata": {
        "id": "plPApwy3ODMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate metrics for negative scouter with lambda = 1\n",
        "calculate_metrics(eval_Imagenet100_negative_lambda1)"
      ],
      "metadata": {
        "id": "fmhdZWJQOE88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate metrics for negative scouter with lambda = 3\n",
        "calculate_metrics(eval_Imagenet100_negative_lambda1)"
      ],
      "metadata": {
        "id": "L5QRVW0xOIQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate metrics for negative scouter with lambda = 10\n",
        "calculate_metrics(eval_Imagenet100_negative_lambda1)"
      ],
      "metadata": {
        "id": "jLtmDodQOJHY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}